// Generated by the protocol buffer compiler.  DO NOT EDIT!
// source: tensorflow/core/protobuf/rewriter_config.proto

package org.tensorflow.framework;

/**
 * <pre>
 * Graph rewriting is experimental and subject to change, not covered by any
 * API stability guarantees.
 * </pre>
 *
 * Protobuf type {@code tensorflow.RewriterConfig}
 */
public  final class RewriterConfig extends
    com.google.protobuf.GeneratedMessageV3 implements
    // @@protoc_insertion_point(message_implements:tensorflow.RewriterConfig)
    RewriterConfigOrBuilder {
  // Use RewriterConfig.newBuilder() to construct.
  private RewriterConfig(com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
    super(builder);
  }
  private RewriterConfig() {
    layoutOptimizer_ = 0;
    constantFolding_ = 0;
    arithmeticOptimization_ = 0;
    dependencyOptimization_ = 0;
    loopOptimization_ = 0;
    functionOptimization_ = 0;
    debugStripper_ = 0;
    disableModelPruning_ = false;
    metaOptimizerIterations_ = 0;
    memoryOptimization_ = 0;
    memoryOptimizerTargetNodeNameScope_ = "";
    optimizers_ = com.google.protobuf.LazyStringArrayList.EMPTY;
  }

  @java.lang.Override
  public final com.google.protobuf.UnknownFieldSet
  getUnknownFields() {
    return com.google.protobuf.UnknownFieldSet.getDefaultInstance();
  }
  private RewriterConfig(
      com.google.protobuf.CodedInputStream input,
      com.google.protobuf.ExtensionRegistryLite extensionRegistry)
      throws com.google.protobuf.InvalidProtocolBufferException {
    this();
    int mutable_bitField0_ = 0;
    try {
      boolean done = false;
      while (!done) {
        int tag = input.readTag();
        switch (tag) {
          case 0:
            done = true;
            break;
          default: {
            if (!input.skipField(tag)) {
              done = true;
            }
            break;
          }
          case 8: {
            int rawValue = input.readEnum();

            layoutOptimizer_ = rawValue;
            break;
          }
          case 16: {

            disableModelPruning_ = input.readBool();
            break;
          }
          case 24: {
            int rawValue = input.readEnum();

            constantFolding_ = rawValue;
            break;
          }
          case 32: {
            int rawValue = input.readEnum();

            memoryOptimization_ = rawValue;
            break;
          }
          case 42: {
            org.tensorflow.framework.AutoParallelOptions.Builder subBuilder = null;
            if (autoParallel_ != null) {
              subBuilder = autoParallel_.toBuilder();
            }
            autoParallel_ = input.readMessage(org.tensorflow.framework.AutoParallelOptions.parser(), extensionRegistry);
            if (subBuilder != null) {
              subBuilder.mergeFrom(autoParallel_);
              autoParallel_ = subBuilder.buildPartial();
            }

            break;
          }
          case 50: {
            java.lang.String s = input.readStringRequireUtf8();

            memoryOptimizerTargetNodeNameScope_ = s;
            break;
          }
          case 56: {
            int rawValue = input.readEnum();

            arithmeticOptimization_ = rawValue;
            break;
          }
          case 64: {
            int rawValue = input.readEnum();

            dependencyOptimization_ = rawValue;
            break;
          }
          case 72: {
            int rawValue = input.readEnum();

            loopOptimization_ = rawValue;
            break;
          }
          case 80: {
            int rawValue = input.readEnum();

            functionOptimization_ = rawValue;
            break;
          }
          case 88: {
            int rawValue = input.readEnum();

            debugStripper_ = rawValue;
            break;
          }
          case 96: {
            int rawValue = input.readEnum();

            metaOptimizerIterations_ = rawValue;
            break;
          }
          case 802: {
            java.lang.String s = input.readStringRequireUtf8();
            if (!((mutable_bitField0_ & 0x00001000) == 0x00001000)) {
              optimizers_ = new com.google.protobuf.LazyStringArrayList();
              mutable_bitField0_ |= 0x00001000;
            }
            optimizers_.add(s);
            break;
          }
        }
      }
    } catch (com.google.protobuf.InvalidProtocolBufferException e) {
      throw e.setUnfinishedMessage(this);
    } catch (java.io.IOException e) {
      throw new com.google.protobuf.InvalidProtocolBufferException(
          e).setUnfinishedMessage(this);
    } finally {
      if (((mutable_bitField0_ & 0x00001000) == 0x00001000)) {
        optimizers_ = optimizers_.getUnmodifiableView();
      }
      makeExtensionsImmutable();
    }
  }
  public static final com.google.protobuf.Descriptors.Descriptor
      getDescriptor() {
    return org.tensorflow.framework.RewriterConfigProtos.internal_static_tensorflow_RewriterConfig_descriptor;
  }

  protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internalGetFieldAccessorTable() {
    return org.tensorflow.framework.RewriterConfigProtos.internal_static_tensorflow_RewriterConfig_fieldAccessorTable
        .ensureFieldAccessorsInitialized(
            org.tensorflow.framework.RewriterConfig.class, org.tensorflow.framework.RewriterConfig.Builder.class);
  }

  /**
   * Protobuf enum {@code tensorflow.RewriterConfig.Toggle}
   */
  public enum Toggle
      implements com.google.protobuf.ProtocolMessageEnum {
    /**
     * <code>DEFAULT = 0;</code>
     */
    DEFAULT(0),
    /**
     * <code>ON = 1;</code>
     */
    ON(1),
    /**
     * <code>OFF = 2;</code>
     */
    OFF(2),
    /**
     * <pre>
     * Enable some aggressive optimizations that use assumptions that TF graphs
     * may break. For example, assume the shape of a placeholder matches its
     * actual feed.
     * </pre>
     *
     * <code>AGGRESSIVE = 3;</code>
     */
    AGGRESSIVE(3),
    UNRECOGNIZED(-1),
    ;

    /**
     * <code>DEFAULT = 0;</code>
     */
    public static final int DEFAULT_VALUE = 0;
    /**
     * <code>ON = 1;</code>
     */
    public static final int ON_VALUE = 1;
    /**
     * <code>OFF = 2;</code>
     */
    public static final int OFF_VALUE = 2;
    /**
     * <pre>
     * Enable some aggressive optimizations that use assumptions that TF graphs
     * may break. For example, assume the shape of a placeholder matches its
     * actual feed.
     * </pre>
     *
     * <code>AGGRESSIVE = 3;</code>
     */
    public static final int AGGRESSIVE_VALUE = 3;


    public final int getNumber() {
      if (this == UNRECOGNIZED) {
        throw new java.lang.IllegalArgumentException(
            "Can't get the number of an unknown enum value.");
      }
      return value;
    }

    /**
     * @deprecated Use {@link #forNumber(int)} instead.
     */
    @java.lang.Deprecated
    public static Toggle valueOf(int value) {
      return forNumber(value);
    }

    public static Toggle forNumber(int value) {
      switch (value) {
        case 0: return DEFAULT;
        case 1: return ON;
        case 2: return OFF;
        case 3: return AGGRESSIVE;
        default: return null;
      }
    }

    public static com.google.protobuf.Internal.EnumLiteMap<Toggle>
        internalGetValueMap() {
      return internalValueMap;
    }
    private static final com.google.protobuf.Internal.EnumLiteMap<
        Toggle> internalValueMap =
          new com.google.protobuf.Internal.EnumLiteMap<Toggle>() {
            public Toggle findValueByNumber(int number) {
              return Toggle.forNumber(number);
            }
          };

    public final com.google.protobuf.Descriptors.EnumValueDescriptor
        getValueDescriptor() {
      return getDescriptor().getValues().get(ordinal());
    }
    public final com.google.protobuf.Descriptors.EnumDescriptor
        getDescriptorForType() {
      return getDescriptor();
    }
    public static final com.google.protobuf.Descriptors.EnumDescriptor
        getDescriptor() {
      return org.tensorflow.framework.RewriterConfig.getDescriptor().getEnumTypes().get(0);
    }

    private static final Toggle[] VALUES = values();

    public static Toggle valueOf(
        com.google.protobuf.Descriptors.EnumValueDescriptor desc) {
      if (desc.getType() != getDescriptor()) {
        throw new java.lang.IllegalArgumentException(
          "EnumValueDescriptor is not for this type.");
      }
      if (desc.getIndex() == -1) {
        return UNRECOGNIZED;
      }
      return VALUES[desc.getIndex()];
    }

    private final int value;

    private Toggle(int value) {
      this.value = value;
    }

    // @@protoc_insertion_point(enum_scope:tensorflow.RewriterConfig.Toggle)
  }

  /**
   * <pre>
   * Enum controling the number of times to run optimizers. The default is to
   * run them once.
   * </pre>
   *
   * Protobuf enum {@code tensorflow.RewriterConfig.NumIterationsType}
   */
  public enum NumIterationsType
      implements com.google.protobuf.ProtocolMessageEnum {
    /**
     * <code>DEFAULT_NUM_ITERS = 0;</code>
     */
    DEFAULT_NUM_ITERS(0),
    /**
     * <code>ONE = 1;</code>
     */
    ONE(1),
    /**
     * <code>TWO = 2;</code>
     */
    TWO(2),
    UNRECOGNIZED(-1),
    ;

    /**
     * <code>DEFAULT_NUM_ITERS = 0;</code>
     */
    public static final int DEFAULT_NUM_ITERS_VALUE = 0;
    /**
     * <code>ONE = 1;</code>
     */
    public static final int ONE_VALUE = 1;
    /**
     * <code>TWO = 2;</code>
     */
    public static final int TWO_VALUE = 2;


    public final int getNumber() {
      if (this == UNRECOGNIZED) {
        throw new java.lang.IllegalArgumentException(
            "Can't get the number of an unknown enum value.");
      }
      return value;
    }

    /**
     * @deprecated Use {@link #forNumber(int)} instead.
     */
    @java.lang.Deprecated
    public static NumIterationsType valueOf(int value) {
      return forNumber(value);
    }

    public static NumIterationsType forNumber(int value) {
      switch (value) {
        case 0: return DEFAULT_NUM_ITERS;
        case 1: return ONE;
        case 2: return TWO;
        default: return null;
      }
    }

    public static com.google.protobuf.Internal.EnumLiteMap<NumIterationsType>
        internalGetValueMap() {
      return internalValueMap;
    }
    private static final com.google.protobuf.Internal.EnumLiteMap<
        NumIterationsType> internalValueMap =
          new com.google.protobuf.Internal.EnumLiteMap<NumIterationsType>() {
            public NumIterationsType findValueByNumber(int number) {
              return NumIterationsType.forNumber(number);
            }
          };

    public final com.google.protobuf.Descriptors.EnumValueDescriptor
        getValueDescriptor() {
      return getDescriptor().getValues().get(ordinal());
    }
    public final com.google.protobuf.Descriptors.EnumDescriptor
        getDescriptorForType() {
      return getDescriptor();
    }
    public static final com.google.protobuf.Descriptors.EnumDescriptor
        getDescriptor() {
      return org.tensorflow.framework.RewriterConfig.getDescriptor().getEnumTypes().get(1);
    }

    private static final NumIterationsType[] VALUES = values();

    public static NumIterationsType valueOf(
        com.google.protobuf.Descriptors.EnumValueDescriptor desc) {
      if (desc.getType() != getDescriptor()) {
        throw new java.lang.IllegalArgumentException(
          "EnumValueDescriptor is not for this type.");
      }
      if (desc.getIndex() == -1) {
        return UNRECOGNIZED;
      }
      return VALUES[desc.getIndex()];
    }

    private final int value;

    private NumIterationsType(int value) {
      this.value = value;
    }

    // @@protoc_insertion_point(enum_scope:tensorflow.RewriterConfig.NumIterationsType)
  }

  /**
   * Protobuf enum {@code tensorflow.RewriterConfig.MemOptType}
   */
  public enum MemOptType
      implements com.google.protobuf.ProtocolMessageEnum {
    /**
     * <pre>
     * The default setting (SCHEDULING and SWAPPING HEURISTICS only)
     * </pre>
     *
     * <code>DEFAULT_MEM_OPT = 0;</code>
     */
    DEFAULT_MEM_OPT(0),
    /**
     * <pre>
     * Disabled in the meta-optimizer.
     * </pre>
     *
     * <code>NO_MEM_OPT = 1;</code>
     */
    NO_MEM_OPT(1),
    /**
     * <pre>
     * Driven by manual op-level annotations.
     * </pre>
     *
     * <code>MANUAL = 2;</code>
     */
    MANUAL(2),
    /**
     * <pre>
     * Swapping heuristic will move a tensor from the GPU to the CPU and move
     * it back when needed to reduce peak memory usage.
     * </pre>
     *
     * <code>SWAPPING_HEURISTICS = 4;</code>
     */
    SWAPPING_HEURISTICS(4),
    /**
     * <pre>
     * Recomputation heuristics will recompute ops (such as Relu activation)
     * during backprop instead of storing them, reducing peak memory usage.
     * </pre>
     *
     * <code>RECOMPUTATION_HEURISTICS = 5;</code>
     */
    RECOMPUTATION_HEURISTICS(5),
    /**
     * <pre>
     * Scheduling will split big ops such as AddN and try to enforce a schedule
     * of the new computations that decreases peak memory usage.
     * </pre>
     *
     * <code>SCHEDULING_HEURISTICS = 6;</code>
     */
    SCHEDULING_HEURISTICS(6),
    /**
     * <pre>
     * Use any combination of swapping and recomputation heuristics.
     * </pre>
     *
     * <code>HEURISTICS = 3;</code>
     */
    HEURISTICS(3),
    UNRECOGNIZED(-1),
    ;

    /**
     * <pre>
     * The default setting (SCHEDULING and SWAPPING HEURISTICS only)
     * </pre>
     *
     * <code>DEFAULT_MEM_OPT = 0;</code>
     */
    public static final int DEFAULT_MEM_OPT_VALUE = 0;
    /**
     * <pre>
     * Disabled in the meta-optimizer.
     * </pre>
     *
     * <code>NO_MEM_OPT = 1;</code>
     */
    public static final int NO_MEM_OPT_VALUE = 1;
    /**
     * <pre>
     * Driven by manual op-level annotations.
     * </pre>
     *
     * <code>MANUAL = 2;</code>
     */
    public static final int MANUAL_VALUE = 2;
    /**
     * <pre>
     * Swapping heuristic will move a tensor from the GPU to the CPU and move
     * it back when needed to reduce peak memory usage.
     * </pre>
     *
     * <code>SWAPPING_HEURISTICS = 4;</code>
     */
    public static final int SWAPPING_HEURISTICS_VALUE = 4;
    /**
     * <pre>
     * Recomputation heuristics will recompute ops (such as Relu activation)
     * during backprop instead of storing them, reducing peak memory usage.
     * </pre>
     *
     * <code>RECOMPUTATION_HEURISTICS = 5;</code>
     */
    public static final int RECOMPUTATION_HEURISTICS_VALUE = 5;
    /**
     * <pre>
     * Scheduling will split big ops such as AddN and try to enforce a schedule
     * of the new computations that decreases peak memory usage.
     * </pre>
     *
     * <code>SCHEDULING_HEURISTICS = 6;</code>
     */
    public static final int SCHEDULING_HEURISTICS_VALUE = 6;
    /**
     * <pre>
     * Use any combination of swapping and recomputation heuristics.
     * </pre>
     *
     * <code>HEURISTICS = 3;</code>
     */
    public static final int HEURISTICS_VALUE = 3;


    public final int getNumber() {
      if (this == UNRECOGNIZED) {
        throw new java.lang.IllegalArgumentException(
            "Can't get the number of an unknown enum value.");
      }
      return value;
    }

    /**
     * @deprecated Use {@link #forNumber(int)} instead.
     */
    @java.lang.Deprecated
    public static MemOptType valueOf(int value) {
      return forNumber(value);
    }

    public static MemOptType forNumber(int value) {
      switch (value) {
        case 0: return DEFAULT_MEM_OPT;
        case 1: return NO_MEM_OPT;
        case 2: return MANUAL;
        case 4: return SWAPPING_HEURISTICS;
        case 5: return RECOMPUTATION_HEURISTICS;
        case 6: return SCHEDULING_HEURISTICS;
        case 3: return HEURISTICS;
        default: return null;
      }
    }

    public static com.google.protobuf.Internal.EnumLiteMap<MemOptType>
        internalGetValueMap() {
      return internalValueMap;
    }
    private static final com.google.protobuf.Internal.EnumLiteMap<
        MemOptType> internalValueMap =
          new com.google.protobuf.Internal.EnumLiteMap<MemOptType>() {
            public MemOptType findValueByNumber(int number) {
              return MemOptType.forNumber(number);
            }
          };

    public final com.google.protobuf.Descriptors.EnumValueDescriptor
        getValueDescriptor() {
      return getDescriptor().getValues().get(ordinal());
    }
    public final com.google.protobuf.Descriptors.EnumDescriptor
        getDescriptorForType() {
      return getDescriptor();
    }
    public static final com.google.protobuf.Descriptors.EnumDescriptor
        getDescriptor() {
      return org.tensorflow.framework.RewriterConfig.getDescriptor().getEnumTypes().get(2);
    }

    private static final MemOptType[] VALUES = values();

    public static MemOptType valueOf(
        com.google.protobuf.Descriptors.EnumValueDescriptor desc) {
      if (desc.getType() != getDescriptor()) {
        throw new java.lang.IllegalArgumentException(
          "EnumValueDescriptor is not for this type.");
      }
      if (desc.getIndex() == -1) {
        return UNRECOGNIZED;
      }
      return VALUES[desc.getIndex()];
    }

    private final int value;

    private MemOptType(int value) {
      this.value = value;
    }

    // @@protoc_insertion_point(enum_scope:tensorflow.RewriterConfig.MemOptType)
  }

  private int bitField0_;
  public static final int LAYOUT_OPTIMIZER_FIELD_NUMBER = 1;
  private int layoutOptimizer_;
  /**
   * <pre>
   * Optimize tensor layouts (default is ON)
   * e.g. This will try to use NCHW layout on GPU which is faster.
   * </pre>
   *
   * <code>.tensorflow.RewriterConfig.Toggle layout_optimizer = 1;</code>
   */
  public int getLayoutOptimizerValue() {
    return layoutOptimizer_;
  }
  /**
   * <pre>
   * Optimize tensor layouts (default is ON)
   * e.g. This will try to use NCHW layout on GPU which is faster.
   * </pre>
   *
   * <code>.tensorflow.RewriterConfig.Toggle layout_optimizer = 1;</code>
   */
  public org.tensorflow.framework.RewriterConfig.Toggle getLayoutOptimizer() {
    org.tensorflow.framework.RewriterConfig.Toggle result = org.tensorflow.framework.RewriterConfig.Toggle.valueOf(layoutOptimizer_);
    return result == null ? org.tensorflow.framework.RewriterConfig.Toggle.UNRECOGNIZED : result;
  }

  public static final int CONSTANT_FOLDING_FIELD_NUMBER = 3;
  private int constantFolding_;
  /**
   * <pre>
   * Fold constants (default is ON)
   * Statically infer the value of tensors when possible, and materialize the
   * result using constants.
   * </pre>
   *
   * <code>.tensorflow.RewriterConfig.Toggle constant_folding = 3;</code>
   */
  public int getConstantFoldingValue() {
    return constantFolding_;
  }
  /**
   * <pre>
   * Fold constants (default is ON)
   * Statically infer the value of tensors when possible, and materialize the
   * result using constants.
   * </pre>
   *
   * <code>.tensorflow.RewriterConfig.Toggle constant_folding = 3;</code>
   */
  public org.tensorflow.framework.RewriterConfig.Toggle getConstantFolding() {
    org.tensorflow.framework.RewriterConfig.Toggle result = org.tensorflow.framework.RewriterConfig.Toggle.valueOf(constantFolding_);
    return result == null ? org.tensorflow.framework.RewriterConfig.Toggle.UNRECOGNIZED : result;
  }

  public static final int ARITHMETIC_OPTIMIZATION_FIELD_NUMBER = 7;
  private int arithmeticOptimization_;
  /**
   * <pre>
   * Arithmetic optimizations (default is ON)
   * e.g. Simplify arithmetic ops; merge ops with same value (like constants).
   * </pre>
   *
   * <code>.tensorflow.RewriterConfig.Toggle arithmetic_optimization = 7;</code>
   */
  public int getArithmeticOptimizationValue() {
    return arithmeticOptimization_;
  }
  /**
   * <pre>
   * Arithmetic optimizations (default is ON)
   * e.g. Simplify arithmetic ops; merge ops with same value (like constants).
   * </pre>
   *
   * <code>.tensorflow.RewriterConfig.Toggle arithmetic_optimization = 7;</code>
   */
  public org.tensorflow.framework.RewriterConfig.Toggle getArithmeticOptimization() {
    org.tensorflow.framework.RewriterConfig.Toggle result = org.tensorflow.framework.RewriterConfig.Toggle.valueOf(arithmeticOptimization_);
    return result == null ? org.tensorflow.framework.RewriterConfig.Toggle.UNRECOGNIZED : result;
  }

  public static final int DEPENDENCY_OPTIMIZATION_FIELD_NUMBER = 8;
  private int dependencyOptimization_;
  /**
   * <pre>
   * Control dependency optimizations (default is ON).
   * Remove redundant control dependencies, which may enable other optimization.
   * </pre>
   *
   * <code>.tensorflow.RewriterConfig.Toggle dependency_optimization = 8;</code>
   */
  public int getDependencyOptimizationValue() {
    return dependencyOptimization_;
  }
  /**
   * <pre>
   * Control dependency optimizations (default is ON).
   * Remove redundant control dependencies, which may enable other optimization.
   * </pre>
   *
   * <code>.tensorflow.RewriterConfig.Toggle dependency_optimization = 8;</code>
   */
  public org.tensorflow.framework.RewriterConfig.Toggle getDependencyOptimization() {
    org.tensorflow.framework.RewriterConfig.Toggle result = org.tensorflow.framework.RewriterConfig.Toggle.valueOf(dependencyOptimization_);
    return result == null ? org.tensorflow.framework.RewriterConfig.Toggle.UNRECOGNIZED : result;
  }

  public static final int LOOP_OPTIMIZATION_FIELD_NUMBER = 9;
  private int loopOptimization_;
  /**
   * <pre>
   * Loop optimizations (default is ON).
   * </pre>
   *
   * <code>.tensorflow.RewriterConfig.Toggle loop_optimization = 9;</code>
   */
  public int getLoopOptimizationValue() {
    return loopOptimization_;
  }
  /**
   * <pre>
   * Loop optimizations (default is ON).
   * </pre>
   *
   * <code>.tensorflow.RewriterConfig.Toggle loop_optimization = 9;</code>
   */
  public org.tensorflow.framework.RewriterConfig.Toggle getLoopOptimization() {
    org.tensorflow.framework.RewriterConfig.Toggle result = org.tensorflow.framework.RewriterConfig.Toggle.valueOf(loopOptimization_);
    return result == null ? org.tensorflow.framework.RewriterConfig.Toggle.UNRECOGNIZED : result;
  }

  public static final int FUNCTION_OPTIMIZATION_FIELD_NUMBER = 10;
  private int functionOptimization_;
  /**
   * <pre>
   * Function optimizations (default is ON).
   * </pre>
   *
   * <code>.tensorflow.RewriterConfig.Toggle function_optimization = 10;</code>
   */
  public int getFunctionOptimizationValue() {
    return functionOptimization_;
  }
  /**
   * <pre>
   * Function optimizations (default is ON).
   * </pre>
   *
   * <code>.tensorflow.RewriterConfig.Toggle function_optimization = 10;</code>
   */
  public org.tensorflow.framework.RewriterConfig.Toggle getFunctionOptimization() {
    org.tensorflow.framework.RewriterConfig.Toggle result = org.tensorflow.framework.RewriterConfig.Toggle.valueOf(functionOptimization_);
    return result == null ? org.tensorflow.framework.RewriterConfig.Toggle.UNRECOGNIZED : result;
  }

  public static final int DEBUG_STRIPPER_FIELD_NUMBER = 11;
  private int debugStripper_;
  /**
   * <pre>
   * Strips debug-related nodes from the graph (off by default).
   * </pre>
   *
   * <code>.tensorflow.RewriterConfig.Toggle debug_stripper = 11;</code>
   */
  public int getDebugStripperValue() {
    return debugStripper_;
  }
  /**
   * <pre>
   * Strips debug-related nodes from the graph (off by default).
   * </pre>
   *
   * <code>.tensorflow.RewriterConfig.Toggle debug_stripper = 11;</code>
   */
  public org.tensorflow.framework.RewriterConfig.Toggle getDebugStripper() {
    org.tensorflow.framework.RewriterConfig.Toggle result = org.tensorflow.framework.RewriterConfig.Toggle.valueOf(debugStripper_);
    return result == null ? org.tensorflow.framework.RewriterConfig.Toggle.UNRECOGNIZED : result;
  }

  public static final int DISABLE_MODEL_PRUNING_FIELD_NUMBER = 2;
  private boolean disableModelPruning_;
  /**
   * <pre>
   * If true, don't remove unnecessary ops from the graph
   * </pre>
   *
   * <code>bool disable_model_pruning = 2;</code>
   */
  public boolean getDisableModelPruning() {
    return disableModelPruning_;
  }

  public static final int META_OPTIMIZER_ITERATIONS_FIELD_NUMBER = 12;
  private int metaOptimizerIterations_;
  /**
   * <pre>
   * Controls how many times we run the optimizers in meta optimizer (default
   * is once).
   * </pre>
   *
   * <code>.tensorflow.RewriterConfig.NumIterationsType meta_optimizer_iterations = 12;</code>
   */
  public int getMetaOptimizerIterationsValue() {
    return metaOptimizerIterations_;
  }
  /**
   * <pre>
   * Controls how many times we run the optimizers in meta optimizer (default
   * is once).
   * </pre>
   *
   * <code>.tensorflow.RewriterConfig.NumIterationsType meta_optimizer_iterations = 12;</code>
   */
  public org.tensorflow.framework.RewriterConfig.NumIterationsType getMetaOptimizerIterations() {
    org.tensorflow.framework.RewriterConfig.NumIterationsType result = org.tensorflow.framework.RewriterConfig.NumIterationsType.valueOf(metaOptimizerIterations_);
    return result == null ? org.tensorflow.framework.RewriterConfig.NumIterationsType.UNRECOGNIZED : result;
  }

  public static final int MEMORY_OPTIMIZATION_FIELD_NUMBER = 4;
  private int memoryOptimization_;
  /**
   * <pre>
   * Configures memory optimization passes through the meta-optimizer. Has no
   * effect on manually requested memory optimization passes in the optimizers
   * field.
   * </pre>
   *
   * <code>.tensorflow.RewriterConfig.MemOptType memory_optimization = 4;</code>
   */
  public int getMemoryOptimizationValue() {
    return memoryOptimization_;
  }
  /**
   * <pre>
   * Configures memory optimization passes through the meta-optimizer. Has no
   * effect on manually requested memory optimization passes in the optimizers
   * field.
   * </pre>
   *
   * <code>.tensorflow.RewriterConfig.MemOptType memory_optimization = 4;</code>
   */
  public org.tensorflow.framework.RewriterConfig.MemOptType getMemoryOptimization() {
    org.tensorflow.framework.RewriterConfig.MemOptType result = org.tensorflow.framework.RewriterConfig.MemOptType.valueOf(memoryOptimization_);
    return result == null ? org.tensorflow.framework.RewriterConfig.MemOptType.UNRECOGNIZED : result;
  }

  public static final int MEMORY_OPTIMIZER_TARGET_NODE_NAME_SCOPE_FIELD_NUMBER = 6;
  private volatile java.lang.Object memoryOptimizerTargetNodeNameScope_;
  /**
   * <pre>
   * A node name scope for node names which are valid outputs of recompuations.
   * Inputs to nodes that match this scope may be recomputed (subject either to
   * manual annotation of those input nodes or to manual annotation and
   * heuristics depending on memory_optimization), but the nodes themselves will
   * not be recomputed. This matches any sub-scopes as well, meaning the scope
   * can appear not just as a top-level scope. For example, if the value is
   * "gradients/", the default, it will match node name "gradients/foo",
   * "foo/gradients/bar", but not "foo_gradients/"
   * </pre>
   *
   * <code>string memory_optimizer_target_node_name_scope = 6;</code>
   */
  public java.lang.String getMemoryOptimizerTargetNodeNameScope() {
    java.lang.Object ref = memoryOptimizerTargetNodeNameScope_;
    if (ref instanceof java.lang.String) {
      return (java.lang.String) ref;
    } else {
      com.google.protobuf.ByteString bs = 
          (com.google.protobuf.ByteString) ref;
      java.lang.String s = bs.toStringUtf8();
      memoryOptimizerTargetNodeNameScope_ = s;
      return s;
    }
  }
  /**
   * <pre>
   * A node name scope for node names which are valid outputs of recompuations.
   * Inputs to nodes that match this scope may be recomputed (subject either to
   * manual annotation of those input nodes or to manual annotation and
   * heuristics depending on memory_optimization), but the nodes themselves will
   * not be recomputed. This matches any sub-scopes as well, meaning the scope
   * can appear not just as a top-level scope. For example, if the value is
   * "gradients/", the default, it will match node name "gradients/foo",
   * "foo/gradients/bar", but not "foo_gradients/"
   * </pre>
   *
   * <code>string memory_optimizer_target_node_name_scope = 6;</code>
   */
  public com.google.protobuf.ByteString
      getMemoryOptimizerTargetNodeNameScopeBytes() {
    java.lang.Object ref = memoryOptimizerTargetNodeNameScope_;
    if (ref instanceof java.lang.String) {
      com.google.protobuf.ByteString b = 
          com.google.protobuf.ByteString.copyFromUtf8(
              (java.lang.String) ref);
      memoryOptimizerTargetNodeNameScope_ = b;
      return b;
    } else {
      return (com.google.protobuf.ByteString) ref;
    }
  }

  public static final int AUTO_PARALLEL_FIELD_NUMBER = 5;
  private org.tensorflow.framework.AutoParallelOptions autoParallel_;
  /**
   * <pre>
   * Configures AutoParallel optimization passes either through the
   * meta-optimizer or when manually specified through the optimizers field.
   * </pre>
   *
   * <code>.tensorflow.AutoParallelOptions auto_parallel = 5;</code>
   */
  public boolean hasAutoParallel() {
    return autoParallel_ != null;
  }
  /**
   * <pre>
   * Configures AutoParallel optimization passes either through the
   * meta-optimizer or when manually specified through the optimizers field.
   * </pre>
   *
   * <code>.tensorflow.AutoParallelOptions auto_parallel = 5;</code>
   */
  public org.tensorflow.framework.AutoParallelOptions getAutoParallel() {
    return autoParallel_ == null ? org.tensorflow.framework.AutoParallelOptions.getDefaultInstance() : autoParallel_;
  }
  /**
   * <pre>
   * Configures AutoParallel optimization passes either through the
   * meta-optimizer or when manually specified through the optimizers field.
   * </pre>
   *
   * <code>.tensorflow.AutoParallelOptions auto_parallel = 5;</code>
   */
  public org.tensorflow.framework.AutoParallelOptionsOrBuilder getAutoParallelOrBuilder() {
    return getAutoParallel();
  }

  public static final int OPTIMIZERS_FIELD_NUMBER = 100;
  private com.google.protobuf.LazyStringList optimizers_;
  /**
   * <pre>
   * If non-empty, will use this as an alternative way to specify a list of
   * optimizations to turn on and the order of the optimizations (replacing the
   * meta-optimizer).
   * Of the RewriterConfig options, only the AutoParallel configuration options
   * (the auto_parallel field) apply to manually requested optimization passes
   * ("autoparallel"). Memory optimization passes ("memory") invoked here are
   * not configurable (in contrast to memory optimization passes through the
   * meta-optimizer) and act only on manual op annotations.
   * Custom registered optimizers will be run after the base optimizers, in
   * the order that they are specified.
   * </pre>
   *
   * <code>repeated string optimizers = 100;</code>
   */
  public com.google.protobuf.ProtocolStringList
      getOptimizersList() {
    return optimizers_;
  }
  /**
   * <pre>
   * If non-empty, will use this as an alternative way to specify a list of
   * optimizations to turn on and the order of the optimizations (replacing the
   * meta-optimizer).
   * Of the RewriterConfig options, only the AutoParallel configuration options
   * (the auto_parallel field) apply to manually requested optimization passes
   * ("autoparallel"). Memory optimization passes ("memory") invoked here are
   * not configurable (in contrast to memory optimization passes through the
   * meta-optimizer) and act only on manual op annotations.
   * Custom registered optimizers will be run after the base optimizers, in
   * the order that they are specified.
   * </pre>
   *
   * <code>repeated string optimizers = 100;</code>
   */
  public int getOptimizersCount() {
    return optimizers_.size();
  }
  /**
   * <pre>
   * If non-empty, will use this as an alternative way to specify a list of
   * optimizations to turn on and the order of the optimizations (replacing the
   * meta-optimizer).
   * Of the RewriterConfig options, only the AutoParallel configuration options
   * (the auto_parallel field) apply to manually requested optimization passes
   * ("autoparallel"). Memory optimization passes ("memory") invoked here are
   * not configurable (in contrast to memory optimization passes through the
   * meta-optimizer) and act only on manual op annotations.
   * Custom registered optimizers will be run after the base optimizers, in
   * the order that they are specified.
   * </pre>
   *
   * <code>repeated string optimizers = 100;</code>
   */
  public java.lang.String getOptimizers(int index) {
    return optimizers_.get(index);
  }
  /**
   * <pre>
   * If non-empty, will use this as an alternative way to specify a list of
   * optimizations to turn on and the order of the optimizations (replacing the
   * meta-optimizer).
   * Of the RewriterConfig options, only the AutoParallel configuration options
   * (the auto_parallel field) apply to manually requested optimization passes
   * ("autoparallel"). Memory optimization passes ("memory") invoked here are
   * not configurable (in contrast to memory optimization passes through the
   * meta-optimizer) and act only on manual op annotations.
   * Custom registered optimizers will be run after the base optimizers, in
   * the order that they are specified.
   * </pre>
   *
   * <code>repeated string optimizers = 100;</code>
   */
  public com.google.protobuf.ByteString
      getOptimizersBytes(int index) {
    return optimizers_.getByteString(index);
  }

  private byte memoizedIsInitialized = -1;
  public final boolean isInitialized() {
    byte isInitialized = memoizedIsInitialized;
    if (isInitialized == 1) return true;
    if (isInitialized == 0) return false;

    memoizedIsInitialized = 1;
    return true;
  }

  public void writeTo(com.google.protobuf.CodedOutputStream output)
                      throws java.io.IOException {
    if (layoutOptimizer_ != org.tensorflow.framework.RewriterConfig.Toggle.DEFAULT.getNumber()) {
      output.writeEnum(1, layoutOptimizer_);
    }
    if (disableModelPruning_ != false) {
      output.writeBool(2, disableModelPruning_);
    }
    if (constantFolding_ != org.tensorflow.framework.RewriterConfig.Toggle.DEFAULT.getNumber()) {
      output.writeEnum(3, constantFolding_);
    }
    if (memoryOptimization_ != org.tensorflow.framework.RewriterConfig.MemOptType.DEFAULT_MEM_OPT.getNumber()) {
      output.writeEnum(4, memoryOptimization_);
    }
    if (autoParallel_ != null) {
      output.writeMessage(5, getAutoParallel());
    }
    if (!getMemoryOptimizerTargetNodeNameScopeBytes().isEmpty()) {
      com.google.protobuf.GeneratedMessageV3.writeString(output, 6, memoryOptimizerTargetNodeNameScope_);
    }
    if (arithmeticOptimization_ != org.tensorflow.framework.RewriterConfig.Toggle.DEFAULT.getNumber()) {
      output.writeEnum(7, arithmeticOptimization_);
    }
    if (dependencyOptimization_ != org.tensorflow.framework.RewriterConfig.Toggle.DEFAULT.getNumber()) {
      output.writeEnum(8, dependencyOptimization_);
    }
    if (loopOptimization_ != org.tensorflow.framework.RewriterConfig.Toggle.DEFAULT.getNumber()) {
      output.writeEnum(9, loopOptimization_);
    }
    if (functionOptimization_ != org.tensorflow.framework.RewriterConfig.Toggle.DEFAULT.getNumber()) {
      output.writeEnum(10, functionOptimization_);
    }
    if (debugStripper_ != org.tensorflow.framework.RewriterConfig.Toggle.DEFAULT.getNumber()) {
      output.writeEnum(11, debugStripper_);
    }
    if (metaOptimizerIterations_ != org.tensorflow.framework.RewriterConfig.NumIterationsType.DEFAULT_NUM_ITERS.getNumber()) {
      output.writeEnum(12, metaOptimizerIterations_);
    }
    for (int i = 0; i < optimizers_.size(); i++) {
      com.google.protobuf.GeneratedMessageV3.writeString(output, 100, optimizers_.getRaw(i));
    }
  }

  public int getSerializedSize() {
    int size = memoizedSize;
    if (size != -1) return size;

    size = 0;
    if (layoutOptimizer_ != org.tensorflow.framework.RewriterConfig.Toggle.DEFAULT.getNumber()) {
      size += com.google.protobuf.CodedOutputStream
        .computeEnumSize(1, layoutOptimizer_);
    }
    if (disableModelPruning_ != false) {
      size += com.google.protobuf.CodedOutputStream
        .computeBoolSize(2, disableModelPruning_);
    }
    if (constantFolding_ != org.tensorflow.framework.RewriterConfig.Toggle.DEFAULT.getNumber()) {
      size += com.google.protobuf.CodedOutputStream
        .computeEnumSize(3, constantFolding_);
    }
    if (memoryOptimization_ != org.tensorflow.framework.RewriterConfig.MemOptType.DEFAULT_MEM_OPT.getNumber()) {
      size += com.google.protobuf.CodedOutputStream
        .computeEnumSize(4, memoryOptimization_);
    }
    if (autoParallel_ != null) {
      size += com.google.protobuf.CodedOutputStream
        .computeMessageSize(5, getAutoParallel());
    }
    if (!getMemoryOptimizerTargetNodeNameScopeBytes().isEmpty()) {
      size += com.google.protobuf.GeneratedMessageV3.computeStringSize(6, memoryOptimizerTargetNodeNameScope_);
    }
    if (arithmeticOptimization_ != org.tensorflow.framework.RewriterConfig.Toggle.DEFAULT.getNumber()) {
      size += com.google.protobuf.CodedOutputStream
        .computeEnumSize(7, arithmeticOptimization_);
    }
    if (dependencyOptimization_ != org.tensorflow.framework.RewriterConfig.Toggle.DEFAULT.getNumber()) {
      size += com.google.protobuf.CodedOutputStream
        .computeEnumSize(8, dependencyOptimization_);
    }
    if (loopOptimization_ != org.tensorflow.framework.RewriterConfig.Toggle.DEFAULT.getNumber()) {
      size += com.google.protobuf.CodedOutputStream
        .computeEnumSize(9, loopOptimization_);
    }
    if (functionOptimization_ != org.tensorflow.framework.RewriterConfig.Toggle.DEFAULT.getNumber()) {
      size += com.google.protobuf.CodedOutputStream
        .computeEnumSize(10, functionOptimization_);
    }
    if (debugStripper_ != org.tensorflow.framework.RewriterConfig.Toggle.DEFAULT.getNumber()) {
      size += com.google.protobuf.CodedOutputStream
        .computeEnumSize(11, debugStripper_);
    }
    if (metaOptimizerIterations_ != org.tensorflow.framework.RewriterConfig.NumIterationsType.DEFAULT_NUM_ITERS.getNumber()) {
      size += com.google.protobuf.CodedOutputStream
        .computeEnumSize(12, metaOptimizerIterations_);
    }
    {
      int dataSize = 0;
      for (int i = 0; i < optimizers_.size(); i++) {
        dataSize += computeStringSizeNoTag(optimizers_.getRaw(i));
      }
      size += dataSize;
      size += 2 * getOptimizersList().size();
    }
    memoizedSize = size;
    return size;
  }

  private static final long serialVersionUID = 0L;
  @java.lang.Override
  public boolean equals(final java.lang.Object obj) {
    if (obj == this) {
     return true;
    }
    if (!(obj instanceof org.tensorflow.framework.RewriterConfig)) {
      return super.equals(obj);
    }
    org.tensorflow.framework.RewriterConfig other = (org.tensorflow.framework.RewriterConfig) obj;

    boolean result = true;
    result = result && layoutOptimizer_ == other.layoutOptimizer_;
    result = result && constantFolding_ == other.constantFolding_;
    result = result && arithmeticOptimization_ == other.arithmeticOptimization_;
    result = result && dependencyOptimization_ == other.dependencyOptimization_;
    result = result && loopOptimization_ == other.loopOptimization_;
    result = result && functionOptimization_ == other.functionOptimization_;
    result = result && debugStripper_ == other.debugStripper_;
    result = result && (getDisableModelPruning()
        == other.getDisableModelPruning());
    result = result && metaOptimizerIterations_ == other.metaOptimizerIterations_;
    result = result && memoryOptimization_ == other.memoryOptimization_;
    result = result && getMemoryOptimizerTargetNodeNameScope()
        .equals(other.getMemoryOptimizerTargetNodeNameScope());
    result = result && (hasAutoParallel() == other.hasAutoParallel());
    if (hasAutoParallel()) {
      result = result && getAutoParallel()
          .equals(other.getAutoParallel());
    }
    result = result && getOptimizersList()
        .equals(other.getOptimizersList());
    return result;
  }

  @java.lang.Override
  public int hashCode() {
    if (memoizedHashCode != 0) {
      return memoizedHashCode;
    }
    int hash = 41;
    hash = (19 * hash) + getDescriptor().hashCode();
    hash = (37 * hash) + LAYOUT_OPTIMIZER_FIELD_NUMBER;
    hash = (53 * hash) + layoutOptimizer_;
    hash = (37 * hash) + CONSTANT_FOLDING_FIELD_NUMBER;
    hash = (53 * hash) + constantFolding_;
    hash = (37 * hash) + ARITHMETIC_OPTIMIZATION_FIELD_NUMBER;
    hash = (53 * hash) + arithmeticOptimization_;
    hash = (37 * hash) + DEPENDENCY_OPTIMIZATION_FIELD_NUMBER;
    hash = (53 * hash) + dependencyOptimization_;
    hash = (37 * hash) + LOOP_OPTIMIZATION_FIELD_NUMBER;
    hash = (53 * hash) + loopOptimization_;
    hash = (37 * hash) + FUNCTION_OPTIMIZATION_FIELD_NUMBER;
    hash = (53 * hash) + functionOptimization_;
    hash = (37 * hash) + DEBUG_STRIPPER_FIELD_NUMBER;
    hash = (53 * hash) + debugStripper_;
    hash = (37 * hash) + DISABLE_MODEL_PRUNING_FIELD_NUMBER;
    hash = (53 * hash) + com.google.protobuf.Internal.hashBoolean(
        getDisableModelPruning());
    hash = (37 * hash) + META_OPTIMIZER_ITERATIONS_FIELD_NUMBER;
    hash = (53 * hash) + metaOptimizerIterations_;
    hash = (37 * hash) + MEMORY_OPTIMIZATION_FIELD_NUMBER;
    hash = (53 * hash) + memoryOptimization_;
    hash = (37 * hash) + MEMORY_OPTIMIZER_TARGET_NODE_NAME_SCOPE_FIELD_NUMBER;
    hash = (53 * hash) + getMemoryOptimizerTargetNodeNameScope().hashCode();
    if (hasAutoParallel()) {
      hash = (37 * hash) + AUTO_PARALLEL_FIELD_NUMBER;
      hash = (53 * hash) + getAutoParallel().hashCode();
    }
    if (getOptimizersCount() > 0) {
      hash = (37 * hash) + OPTIMIZERS_FIELD_NUMBER;
      hash = (53 * hash) + getOptimizersList().hashCode();
    }
    hash = (29 * hash) + unknownFields.hashCode();
    memoizedHashCode = hash;
    return hash;
  }

  public static org.tensorflow.framework.RewriterConfig parseFrom(
      com.google.protobuf.ByteString data)
      throws com.google.protobuf.InvalidProtocolBufferException {
    return PARSER.parseFrom(data);
  }
  public static org.tensorflow.framework.RewriterConfig parseFrom(
      com.google.protobuf.ByteString data,
      com.google.protobuf.ExtensionRegistryLite extensionRegistry)
      throws com.google.protobuf.InvalidProtocolBufferException {
    return PARSER.parseFrom(data, extensionRegistry);
  }
  public static org.tensorflow.framework.RewriterConfig parseFrom(byte[] data)
      throws com.google.protobuf.InvalidProtocolBufferException {
    return PARSER.parseFrom(data);
  }
  public static org.tensorflow.framework.RewriterConfig parseFrom(
      byte[] data,
      com.google.protobuf.ExtensionRegistryLite extensionRegistry)
      throws com.google.protobuf.InvalidProtocolBufferException {
    return PARSER.parseFrom(data, extensionRegistry);
  }
  public static org.tensorflow.framework.RewriterConfig parseFrom(java.io.InputStream input)
      throws java.io.IOException {
    return com.google.protobuf.GeneratedMessageV3
        .parseWithIOException(PARSER, input);
  }
  public static org.tensorflow.framework.RewriterConfig parseFrom(
      java.io.InputStream input,
      com.google.protobuf.ExtensionRegistryLite extensionRegistry)
      throws java.io.IOException {
    return com.google.protobuf.GeneratedMessageV3
        .parseWithIOException(PARSER, input, extensionRegistry);
  }
  public static org.tensorflow.framework.RewriterConfig parseDelimitedFrom(java.io.InputStream input)
      throws java.io.IOException {
    return com.google.protobuf.GeneratedMessageV3
        .parseDelimitedWithIOException(PARSER, input);
  }
  public static org.tensorflow.framework.RewriterConfig parseDelimitedFrom(
      java.io.InputStream input,
      com.google.protobuf.ExtensionRegistryLite extensionRegistry)
      throws java.io.IOException {
    return com.google.protobuf.GeneratedMessageV3
        .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
  }
  public static org.tensorflow.framework.RewriterConfig parseFrom(
      com.google.protobuf.CodedInputStream input)
      throws java.io.IOException {
    return com.google.protobuf.GeneratedMessageV3
        .parseWithIOException(PARSER, input);
  }
  public static org.tensorflow.framework.RewriterConfig parseFrom(
      com.google.protobuf.CodedInputStream input,
      com.google.protobuf.ExtensionRegistryLite extensionRegistry)
      throws java.io.IOException {
    return com.google.protobuf.GeneratedMessageV3
        .parseWithIOException(PARSER, input, extensionRegistry);
  }

  public Builder newBuilderForType() { return newBuilder(); }
  public static Builder newBuilder() {
    return DEFAULT_INSTANCE.toBuilder();
  }
  public static Builder newBuilder(org.tensorflow.framework.RewriterConfig prototype) {
    return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
  }
  public Builder toBuilder() {
    return this == DEFAULT_INSTANCE
        ? new Builder() : new Builder().mergeFrom(this);
  }

  @java.lang.Override
  protected Builder newBuilderForType(
      com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
    Builder builder = new Builder(parent);
    return builder;
  }
  /**
   * <pre>
   * Graph rewriting is experimental and subject to change, not covered by any
   * API stability guarantees.
   * </pre>
   *
   * Protobuf type {@code tensorflow.RewriterConfig}
   */
  public static final class Builder extends
      com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
      // @@protoc_insertion_point(builder_implements:tensorflow.RewriterConfig)
      org.tensorflow.framework.RewriterConfigOrBuilder {
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.tensorflow.framework.RewriterConfigProtos.internal_static_tensorflow_RewriterConfig_descriptor;
    }

    protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.tensorflow.framework.RewriterConfigProtos.internal_static_tensorflow_RewriterConfig_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.tensorflow.framework.RewriterConfig.class, org.tensorflow.framework.RewriterConfig.Builder.class);
    }

    // Construct using org.tensorflow.framework.RewriterConfig.newBuilder()
    private Builder() {
      maybeForceBuilderInitialization();
    }

    private Builder(
        com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      super(parent);
      maybeForceBuilderInitialization();
    }
    private void maybeForceBuilderInitialization() {
      if (com.google.protobuf.GeneratedMessageV3
              .alwaysUseFieldBuilders) {
      }
    }
    public Builder clear() {
      super.clear();
      layoutOptimizer_ = 0;

      constantFolding_ = 0;

      arithmeticOptimization_ = 0;

      dependencyOptimization_ = 0;

      loopOptimization_ = 0;

      functionOptimization_ = 0;

      debugStripper_ = 0;

      disableModelPruning_ = false;

      metaOptimizerIterations_ = 0;

      memoryOptimization_ = 0;

      memoryOptimizerTargetNodeNameScope_ = "";

      if (autoParallelBuilder_ == null) {
        autoParallel_ = null;
      } else {
        autoParallel_ = null;
        autoParallelBuilder_ = null;
      }
      optimizers_ = com.google.protobuf.LazyStringArrayList.EMPTY;
      bitField0_ = (bitField0_ & ~0x00001000);
      return this;
    }

    public com.google.protobuf.Descriptors.Descriptor
        getDescriptorForType() {
      return org.tensorflow.framework.RewriterConfigProtos.internal_static_tensorflow_RewriterConfig_descriptor;
    }

    public org.tensorflow.framework.RewriterConfig getDefaultInstanceForType() {
      return org.tensorflow.framework.RewriterConfig.getDefaultInstance();
    }

    public org.tensorflow.framework.RewriterConfig build() {
      org.tensorflow.framework.RewriterConfig result = buildPartial();
      if (!result.isInitialized()) {
        throw newUninitializedMessageException(result);
      }
      return result;
    }

    public org.tensorflow.framework.RewriterConfig buildPartial() {
      org.tensorflow.framework.RewriterConfig result = new org.tensorflow.framework.RewriterConfig(this);
      int from_bitField0_ = bitField0_;
      int to_bitField0_ = 0;
      result.layoutOptimizer_ = layoutOptimizer_;
      result.constantFolding_ = constantFolding_;
      result.arithmeticOptimization_ = arithmeticOptimization_;
      result.dependencyOptimization_ = dependencyOptimization_;
      result.loopOptimization_ = loopOptimization_;
      result.functionOptimization_ = functionOptimization_;
      result.debugStripper_ = debugStripper_;
      result.disableModelPruning_ = disableModelPruning_;
      result.metaOptimizerIterations_ = metaOptimizerIterations_;
      result.memoryOptimization_ = memoryOptimization_;
      result.memoryOptimizerTargetNodeNameScope_ = memoryOptimizerTargetNodeNameScope_;
      if (autoParallelBuilder_ == null) {
        result.autoParallel_ = autoParallel_;
      } else {
        result.autoParallel_ = autoParallelBuilder_.build();
      }
      if (((bitField0_ & 0x00001000) == 0x00001000)) {
        optimizers_ = optimizers_.getUnmodifiableView();
        bitField0_ = (bitField0_ & ~0x00001000);
      }
      result.optimizers_ = optimizers_;
      result.bitField0_ = to_bitField0_;
      onBuilt();
      return result;
    }

    public Builder clone() {
      return (Builder) super.clone();
    }
    public Builder setField(
        com.google.protobuf.Descriptors.FieldDescriptor field,
        Object value) {
      return (Builder) super.setField(field, value);
    }
    public Builder clearField(
        com.google.protobuf.Descriptors.FieldDescriptor field) {
      return (Builder) super.clearField(field);
    }
    public Builder clearOneof(
        com.google.protobuf.Descriptors.OneofDescriptor oneof) {
      return (Builder) super.clearOneof(oneof);
    }
    public Builder setRepeatedField(
        com.google.protobuf.Descriptors.FieldDescriptor field,
        int index, Object value) {
      return (Builder) super.setRepeatedField(field, index, value);
    }
    public Builder addRepeatedField(
        com.google.protobuf.Descriptors.FieldDescriptor field,
        Object value) {
      return (Builder) super.addRepeatedField(field, value);
    }
    public Builder mergeFrom(com.google.protobuf.Message other) {
      if (other instanceof org.tensorflow.framework.RewriterConfig) {
        return mergeFrom((org.tensorflow.framework.RewriterConfig)other);
      } else {
        super.mergeFrom(other);
        return this;
      }
    }

    public Builder mergeFrom(org.tensorflow.framework.RewriterConfig other) {
      if (other == org.tensorflow.framework.RewriterConfig.getDefaultInstance()) return this;
      if (other.layoutOptimizer_ != 0) {
        setLayoutOptimizerValue(other.getLayoutOptimizerValue());
      }
      if (other.constantFolding_ != 0) {
        setConstantFoldingValue(other.getConstantFoldingValue());
      }
      if (other.arithmeticOptimization_ != 0) {
        setArithmeticOptimizationValue(other.getArithmeticOptimizationValue());
      }
      if (other.dependencyOptimization_ != 0) {
        setDependencyOptimizationValue(other.getDependencyOptimizationValue());
      }
      if (other.loopOptimization_ != 0) {
        setLoopOptimizationValue(other.getLoopOptimizationValue());
      }
      if (other.functionOptimization_ != 0) {
        setFunctionOptimizationValue(other.getFunctionOptimizationValue());
      }
      if (other.debugStripper_ != 0) {
        setDebugStripperValue(other.getDebugStripperValue());
      }
      if (other.getDisableModelPruning() != false) {
        setDisableModelPruning(other.getDisableModelPruning());
      }
      if (other.metaOptimizerIterations_ != 0) {
        setMetaOptimizerIterationsValue(other.getMetaOptimizerIterationsValue());
      }
      if (other.memoryOptimization_ != 0) {
        setMemoryOptimizationValue(other.getMemoryOptimizationValue());
      }
      if (!other.getMemoryOptimizerTargetNodeNameScope().isEmpty()) {
        memoryOptimizerTargetNodeNameScope_ = other.memoryOptimizerTargetNodeNameScope_;
        onChanged();
      }
      if (other.hasAutoParallel()) {
        mergeAutoParallel(other.getAutoParallel());
      }
      if (!other.optimizers_.isEmpty()) {
        if (optimizers_.isEmpty()) {
          optimizers_ = other.optimizers_;
          bitField0_ = (bitField0_ & ~0x00001000);
        } else {
          ensureOptimizersIsMutable();
          optimizers_.addAll(other.optimizers_);
        }
        onChanged();
      }
      onChanged();
      return this;
    }

    public final boolean isInitialized() {
      return true;
    }

    public Builder mergeFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      org.tensorflow.framework.RewriterConfig parsedMessage = null;
      try {
        parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        parsedMessage = (org.tensorflow.framework.RewriterConfig) e.getUnfinishedMessage();
        throw e.unwrapIOException();
      } finally {
        if (parsedMessage != null) {
          mergeFrom(parsedMessage);
        }
      }
      return this;
    }
    private int bitField0_;

    private int layoutOptimizer_ = 0;
    /**
     * <pre>
     * Optimize tensor layouts (default is ON)
     * e.g. This will try to use NCHW layout on GPU which is faster.
     * </pre>
     *
     * <code>.tensorflow.RewriterConfig.Toggle layout_optimizer = 1;</code>
     */
    public int getLayoutOptimizerValue() {
      return layoutOptimizer_;
    }
    /**
     * <pre>
     * Optimize tensor layouts (default is ON)
     * e.g. This will try to use NCHW layout on GPU which is faster.
     * </pre>
     *
     * <code>.tensorflow.RewriterConfig.Toggle layout_optimizer = 1;</code>
     */
    public Builder setLayoutOptimizerValue(int value) {
      layoutOptimizer_ = value;
      onChanged();
      return this;
    }
    /**
     * <pre>
     * Optimize tensor layouts (default is ON)
     * e.g. This will try to use NCHW layout on GPU which is faster.
     * </pre>
     *
     * <code>.tensorflow.RewriterConfig.Toggle layout_optimizer = 1;</code>
     */
    public org.tensorflow.framework.RewriterConfig.Toggle getLayoutOptimizer() {
      org.tensorflow.framework.RewriterConfig.Toggle result = org.tensorflow.framework.RewriterConfig.Toggle.valueOf(layoutOptimizer_);
      return result == null ? org.tensorflow.framework.RewriterConfig.Toggle.UNRECOGNIZED : result;
    }
    /**
     * <pre>
     * Optimize tensor layouts (default is ON)
     * e.g. This will try to use NCHW layout on GPU which is faster.
     * </pre>
     *
     * <code>.tensorflow.RewriterConfig.Toggle layout_optimizer = 1;</code>
     */
    public Builder setLayoutOptimizer(org.tensorflow.framework.RewriterConfig.Toggle value) {
      if (value == null) {
        throw new NullPointerException();
      }
      
      layoutOptimizer_ = value.getNumber();
      onChanged();
      return this;
    }
    /**
     * <pre>
     * Optimize tensor layouts (default is ON)
     * e.g. This will try to use NCHW layout on GPU which is faster.
     * </pre>
     *
     * <code>.tensorflow.RewriterConfig.Toggle layout_optimizer = 1;</code>
     */
    public Builder clearLayoutOptimizer() {
      
      layoutOptimizer_ = 0;
      onChanged();
      return this;
    }

    private int constantFolding_ = 0;
    /**
     * <pre>
     * Fold constants (default is ON)
     * Statically infer the value of tensors when possible, and materialize the
     * result using constants.
     * </pre>
     *
     * <code>.tensorflow.RewriterConfig.Toggle constant_folding = 3;</code>
     */
    public int getConstantFoldingValue() {
      return constantFolding_;
    }
    /**
     * <pre>
     * Fold constants (default is ON)
     * Statically infer the value of tensors when possible, and materialize the
     * result using constants.
     * </pre>
     *
     * <code>.tensorflow.RewriterConfig.Toggle constant_folding = 3;</code>
     */
    public Builder setConstantFoldingValue(int value) {
      constantFolding_ = value;
      onChanged();
      return this;
    }
    /**
     * <pre>
     * Fold constants (default is ON)
     * Statically infer the value of tensors when possible, and materialize the
     * result using constants.
     * </pre>
     *
     * <code>.tensorflow.RewriterConfig.Toggle constant_folding = 3;</code>
     */
    public org.tensorflow.framework.RewriterConfig.Toggle getConstantFolding() {
      org.tensorflow.framework.RewriterConfig.Toggle result = org.tensorflow.framework.RewriterConfig.Toggle.valueOf(constantFolding_);
      return result == null ? org.tensorflow.framework.RewriterConfig.Toggle.UNRECOGNIZED : result;
    }
    /**
     * <pre>
     * Fold constants (default is ON)
     * Statically infer the value of tensors when possible, and materialize the
     * result using constants.
     * </pre>
     *
     * <code>.tensorflow.RewriterConfig.Toggle constant_folding = 3;</code>
     */
    public Builder setConstantFolding(org.tensorflow.framework.RewriterConfig.Toggle value) {
      if (value == null) {
        throw new NullPointerException();
      }
      
      constantFolding_ = value.getNumber();
      onChanged();
      return this;
    }
    /**
     * <pre>
     * Fold constants (default is ON)
     * Statically infer the value of tensors when possible, and materialize the
     * result using constants.
     * </pre>
     *
     * <code>.tensorflow.RewriterConfig.Toggle constant_folding = 3;</code>
     */
    public Builder clearConstantFolding() {
      
      constantFolding_ = 0;
      onChanged();
      return this;
    }

    private int arithmeticOptimization_ = 0;
    /**
     * <pre>
     * Arithmetic optimizations (default is ON)
     * e.g. Simplify arithmetic ops; merge ops with same value (like constants).
     * </pre>
     *
     * <code>.tensorflow.RewriterConfig.Toggle arithmetic_optimization = 7;</code>
     */
    public int getArithmeticOptimizationValue() {
      return arithmeticOptimization_;
    }
    /**
     * <pre>
     * Arithmetic optimizations (default is ON)
     * e.g. Simplify arithmetic ops; merge ops with same value (like constants).
     * </pre>
     *
     * <code>.tensorflow.RewriterConfig.Toggle arithmetic_optimization = 7;</code>
     */
    public Builder setArithmeticOptimizationValue(int value) {
      arithmeticOptimization_ = value;
      onChanged();
      return this;
    }
    /**
     * <pre>
     * Arithmetic optimizations (default is ON)
     * e.g. Simplify arithmetic ops; merge ops with same value (like constants).
     * </pre>
     *
     * <code>.tensorflow.RewriterConfig.Toggle arithmetic_optimization = 7;</code>
     */
    public org.tensorflow.framework.RewriterConfig.Toggle getArithmeticOptimization() {
      org.tensorflow.framework.RewriterConfig.Toggle result = org.tensorflow.framework.RewriterConfig.Toggle.valueOf(arithmeticOptimization_);
      return result == null ? org.tensorflow.framework.RewriterConfig.Toggle.UNRECOGNIZED : result;
    }
    /**
     * <pre>
     * Arithmetic optimizations (default is ON)
     * e.g. Simplify arithmetic ops; merge ops with same value (like constants).
     * </pre>
     *
     * <code>.tensorflow.RewriterConfig.Toggle arithmetic_optimization = 7;</code>
     */
    public Builder setArithmeticOptimization(org.tensorflow.framework.RewriterConfig.Toggle value) {
      if (value == null) {
        throw new NullPointerException();
      }
      
      arithmeticOptimization_ = value.getNumber();
      onChanged();
      return this;
    }
    /**
     * <pre>
     * Arithmetic optimizations (default is ON)
     * e.g. Simplify arithmetic ops; merge ops with same value (like constants).
     * </pre>
     *
     * <code>.tensorflow.RewriterConfig.Toggle arithmetic_optimization = 7;</code>
     */
    public Builder clearArithmeticOptimization() {
      
      arithmeticOptimization_ = 0;
      onChanged();
      return this;
    }

    private int dependencyOptimization_ = 0;
    /**
     * <pre>
     * Control dependency optimizations (default is ON).
     * Remove redundant control dependencies, which may enable other optimization.
     * </pre>
     *
     * <code>.tensorflow.RewriterConfig.Toggle dependency_optimization = 8;</code>
     */
    public int getDependencyOptimizationValue() {
      return dependencyOptimization_;
    }
    /**
     * <pre>
     * Control dependency optimizations (default is ON).
     * Remove redundant control dependencies, which may enable other optimization.
     * </pre>
     *
     * <code>.tensorflow.RewriterConfig.Toggle dependency_optimization = 8;</code>
     */
    public Builder setDependencyOptimizationValue(int value) {
      dependencyOptimization_ = value;
      onChanged();
      return this;
    }
    /**
     * <pre>
     * Control dependency optimizations (default is ON).
     * Remove redundant control dependencies, which may enable other optimization.
     * </pre>
     *
     * <code>.tensorflow.RewriterConfig.Toggle dependency_optimization = 8;</code>
     */
    public org.tensorflow.framework.RewriterConfig.Toggle getDependencyOptimization() {
      org.tensorflow.framework.RewriterConfig.Toggle result = org.tensorflow.framework.RewriterConfig.Toggle.valueOf(dependencyOptimization_);
      return result == null ? org.tensorflow.framework.RewriterConfig.Toggle.UNRECOGNIZED : result;
    }
    /**
     * <pre>
     * Control dependency optimizations (default is ON).
     * Remove redundant control dependencies, which may enable other optimization.
     * </pre>
     *
     * <code>.tensorflow.RewriterConfig.Toggle dependency_optimization = 8;</code>
     */
    public Builder setDependencyOptimization(org.tensorflow.framework.RewriterConfig.Toggle value) {
      if (value == null) {
        throw new NullPointerException();
      }
      
      dependencyOptimization_ = value.getNumber();
      onChanged();
      return this;
    }
    /**
     * <pre>
     * Control dependency optimizations (default is ON).
     * Remove redundant control dependencies, which may enable other optimization.
     * </pre>
     *
     * <code>.tensorflow.RewriterConfig.Toggle dependency_optimization = 8;</code>
     */
    public Builder clearDependencyOptimization() {
      
      dependencyOptimization_ = 0;
      onChanged();
      return this;
    }

    private int loopOptimization_ = 0;
    /**
     * <pre>
     * Loop optimizations (default is ON).
     * </pre>
     *
     * <code>.tensorflow.RewriterConfig.Toggle loop_optimization = 9;</code>
     */
    public int getLoopOptimizationValue() {
      return loopOptimization_;
    }
    /**
     * <pre>
     * Loop optimizations (default is ON).
     * </pre>
     *
     * <code>.tensorflow.RewriterConfig.Toggle loop_optimization = 9;</code>
     */
    public Builder setLoopOptimizationValue(int value) {
      loopOptimization_ = value;
      onChanged();
      return this;
    }
    /**
     * <pre>
     * Loop optimizations (default is ON).
     * </pre>
     *
     * <code>.tensorflow.RewriterConfig.Toggle loop_optimization = 9;</code>
     */
    public org.tensorflow.framework.RewriterConfig.Toggle getLoopOptimization() {
      org.tensorflow.framework.RewriterConfig.Toggle result = org.tensorflow.framework.RewriterConfig.Toggle.valueOf(loopOptimization_);
      return result == null ? org.tensorflow.framework.RewriterConfig.Toggle.UNRECOGNIZED : result;
    }
    /**
     * <pre>
     * Loop optimizations (default is ON).
     * </pre>
     *
     * <code>.tensorflow.RewriterConfig.Toggle loop_optimization = 9;</code>
     */
    public Builder setLoopOptimization(org.tensorflow.framework.RewriterConfig.Toggle value) {
      if (value == null) {
        throw new NullPointerException();
      }
      
      loopOptimization_ = value.getNumber();
      onChanged();
      return this;
    }
    /**
     * <pre>
     * Loop optimizations (default is ON).
     * </pre>
     *
     * <code>.tensorflow.RewriterConfig.Toggle loop_optimization = 9;</code>
     */
    public Builder clearLoopOptimization() {
      
      loopOptimization_ = 0;
      onChanged();
      return this;
    }

    private int functionOptimization_ = 0;
    /**
     * <pre>
     * Function optimizations (default is ON).
     * </pre>
     *
     * <code>.tensorflow.RewriterConfig.Toggle function_optimization = 10;</code>
     */
    public int getFunctionOptimizationValue() {
      return functionOptimization_;
    }
    /**
     * <pre>
     * Function optimizations (default is ON).
     * </pre>
     *
     * <code>.tensorflow.RewriterConfig.Toggle function_optimization = 10;</code>
     */
    public Builder setFunctionOptimizationValue(int value) {
      functionOptimization_ = value;
      onChanged();
      return this;
    }
    /**
     * <pre>
     * Function optimizations (default is ON).
     * </pre>
     *
     * <code>.tensorflow.RewriterConfig.Toggle function_optimization = 10;</code>
     */
    public org.tensorflow.framework.RewriterConfig.Toggle getFunctionOptimization() {
      org.tensorflow.framework.RewriterConfig.Toggle result = org.tensorflow.framework.RewriterConfig.Toggle.valueOf(functionOptimization_);
      return result == null ? org.tensorflow.framework.RewriterConfig.Toggle.UNRECOGNIZED : result;
    }
    /**
     * <pre>
     * Function optimizations (default is ON).
     * </pre>
     *
     * <code>.tensorflow.RewriterConfig.Toggle function_optimization = 10;</code>
     */
    public Builder setFunctionOptimization(org.tensorflow.framework.RewriterConfig.Toggle value) {
      if (value == null) {
        throw new NullPointerException();
      }
      
      functionOptimization_ = value.getNumber();
      onChanged();
      return this;
    }
    /**
     * <pre>
     * Function optimizations (default is ON).
     * </pre>
     *
     * <code>.tensorflow.RewriterConfig.Toggle function_optimization = 10;</code>
     */
    public Builder clearFunctionOptimization() {
      
      functionOptimization_ = 0;
      onChanged();
      return this;
    }

    private int debugStripper_ = 0;
    /**
     * <pre>
     * Strips debug-related nodes from the graph (off by default).
     * </pre>
     *
     * <code>.tensorflow.RewriterConfig.Toggle debug_stripper = 11;</code>
     */
    public int getDebugStripperValue() {
      return debugStripper_;
    }
    /**
     * <pre>
     * Strips debug-related nodes from the graph (off by default).
     * </pre>
     *
     * <code>.tensorflow.RewriterConfig.Toggle debug_stripper = 11;</code>
     */
    public Builder setDebugStripperValue(int value) {
      debugStripper_ = value;
      onChanged();
      return this;
    }
    /**
     * <pre>
     * Strips debug-related nodes from the graph (off by default).
     * </pre>
     *
     * <code>.tensorflow.RewriterConfig.Toggle debug_stripper = 11;</code>
     */
    public org.tensorflow.framework.RewriterConfig.Toggle getDebugStripper() {
      org.tensorflow.framework.RewriterConfig.Toggle result = org.tensorflow.framework.RewriterConfig.Toggle.valueOf(debugStripper_);
      return result == null ? org.tensorflow.framework.RewriterConfig.Toggle.UNRECOGNIZED : result;
    }
    /**
     * <pre>
     * Strips debug-related nodes from the graph (off by default).
     * </pre>
     *
     * <code>.tensorflow.RewriterConfig.Toggle debug_stripper = 11;</code>
     */
    public Builder setDebugStripper(org.tensorflow.framework.RewriterConfig.Toggle value) {
      if (value == null) {
        throw new NullPointerException();
      }
      
      debugStripper_ = value.getNumber();
      onChanged();
      return this;
    }
    /**
     * <pre>
     * Strips debug-related nodes from the graph (off by default).
     * </pre>
     *
     * <code>.tensorflow.RewriterConfig.Toggle debug_stripper = 11;</code>
     */
    public Builder clearDebugStripper() {
      
      debugStripper_ = 0;
      onChanged();
      return this;
    }

    private boolean disableModelPruning_ ;
    /**
     * <pre>
     * If true, don't remove unnecessary ops from the graph
     * </pre>
     *
     * <code>bool disable_model_pruning = 2;</code>
     */
    public boolean getDisableModelPruning() {
      return disableModelPruning_;
    }
    /**
     * <pre>
     * If true, don't remove unnecessary ops from the graph
     * </pre>
     *
     * <code>bool disable_model_pruning = 2;</code>
     */
    public Builder setDisableModelPruning(boolean value) {
      
      disableModelPruning_ = value;
      onChanged();
      return this;
    }
    /**
     * <pre>
     * If true, don't remove unnecessary ops from the graph
     * </pre>
     *
     * <code>bool disable_model_pruning = 2;</code>
     */
    public Builder clearDisableModelPruning() {
      
      disableModelPruning_ = false;
      onChanged();
      return this;
    }

    private int metaOptimizerIterations_ = 0;
    /**
     * <pre>
     * Controls how many times we run the optimizers in meta optimizer (default
     * is once).
     * </pre>
     *
     * <code>.tensorflow.RewriterConfig.NumIterationsType meta_optimizer_iterations = 12;</code>
     */
    public int getMetaOptimizerIterationsValue() {
      return metaOptimizerIterations_;
    }
    /**
     * <pre>
     * Controls how many times we run the optimizers in meta optimizer (default
     * is once).
     * </pre>
     *
     * <code>.tensorflow.RewriterConfig.NumIterationsType meta_optimizer_iterations = 12;</code>
     */
    public Builder setMetaOptimizerIterationsValue(int value) {
      metaOptimizerIterations_ = value;
      onChanged();
      return this;
    }
    /**
     * <pre>
     * Controls how many times we run the optimizers in meta optimizer (default
     * is once).
     * </pre>
     *
     * <code>.tensorflow.RewriterConfig.NumIterationsType meta_optimizer_iterations = 12;</code>
     */
    public org.tensorflow.framework.RewriterConfig.NumIterationsType getMetaOptimizerIterations() {
      org.tensorflow.framework.RewriterConfig.NumIterationsType result = org.tensorflow.framework.RewriterConfig.NumIterationsType.valueOf(metaOptimizerIterations_);
      return result == null ? org.tensorflow.framework.RewriterConfig.NumIterationsType.UNRECOGNIZED : result;
    }
    /**
     * <pre>
     * Controls how many times we run the optimizers in meta optimizer (default
     * is once).
     * </pre>
     *
     * <code>.tensorflow.RewriterConfig.NumIterationsType meta_optimizer_iterations = 12;</code>
     */
    public Builder setMetaOptimizerIterations(org.tensorflow.framework.RewriterConfig.NumIterationsType value) {
      if (value == null) {
        throw new NullPointerException();
      }
      
      metaOptimizerIterations_ = value.getNumber();
      onChanged();
      return this;
    }
    /**
     * <pre>
     * Controls how many times we run the optimizers in meta optimizer (default
     * is once).
     * </pre>
     *
     * <code>.tensorflow.RewriterConfig.NumIterationsType meta_optimizer_iterations = 12;</code>
     */
    public Builder clearMetaOptimizerIterations() {
      
      metaOptimizerIterations_ = 0;
      onChanged();
      return this;
    }

    private int memoryOptimization_ = 0;
    /**
     * <pre>
     * Configures memory optimization passes through the meta-optimizer. Has no
     * effect on manually requested memory optimization passes in the optimizers
     * field.
     * </pre>
     *
     * <code>.tensorflow.RewriterConfig.MemOptType memory_optimization = 4;</code>
     */
    public int getMemoryOptimizationValue() {
      return memoryOptimization_;
    }
    /**
     * <pre>
     * Configures memory optimization passes through the meta-optimizer. Has no
     * effect on manually requested memory optimization passes in the optimizers
     * field.
     * </pre>
     *
     * <code>.tensorflow.RewriterConfig.MemOptType memory_optimization = 4;</code>
     */
    public Builder setMemoryOptimizationValue(int value) {
      memoryOptimization_ = value;
      onChanged();
      return this;
    }
    /**
     * <pre>
     * Configures memory optimization passes through the meta-optimizer. Has no
     * effect on manually requested memory optimization passes in the optimizers
     * field.
     * </pre>
     *
     * <code>.tensorflow.RewriterConfig.MemOptType memory_optimization = 4;</code>
     */
    public org.tensorflow.framework.RewriterConfig.MemOptType getMemoryOptimization() {
      org.tensorflow.framework.RewriterConfig.MemOptType result = org.tensorflow.framework.RewriterConfig.MemOptType.valueOf(memoryOptimization_);
      return result == null ? org.tensorflow.framework.RewriterConfig.MemOptType.UNRECOGNIZED : result;
    }
    /**
     * <pre>
     * Configures memory optimization passes through the meta-optimizer. Has no
     * effect on manually requested memory optimization passes in the optimizers
     * field.
     * </pre>
     *
     * <code>.tensorflow.RewriterConfig.MemOptType memory_optimization = 4;</code>
     */
    public Builder setMemoryOptimization(org.tensorflow.framework.RewriterConfig.MemOptType value) {
      if (value == null) {
        throw new NullPointerException();
      }
      
      memoryOptimization_ = value.getNumber();
      onChanged();
      return this;
    }
    /**
     * <pre>
     * Configures memory optimization passes through the meta-optimizer. Has no
     * effect on manually requested memory optimization passes in the optimizers
     * field.
     * </pre>
     *
     * <code>.tensorflow.RewriterConfig.MemOptType memory_optimization = 4;</code>
     */
    public Builder clearMemoryOptimization() {
      
      memoryOptimization_ = 0;
      onChanged();
      return this;
    }

    private java.lang.Object memoryOptimizerTargetNodeNameScope_ = "";
    /**
     * <pre>
     * A node name scope for node names which are valid outputs of recompuations.
     * Inputs to nodes that match this scope may be recomputed (subject either to
     * manual annotation of those input nodes or to manual annotation and
     * heuristics depending on memory_optimization), but the nodes themselves will
     * not be recomputed. This matches any sub-scopes as well, meaning the scope
     * can appear not just as a top-level scope. For example, if the value is
     * "gradients/", the default, it will match node name "gradients/foo",
     * "foo/gradients/bar", but not "foo_gradients/"
     * </pre>
     *
     * <code>string memory_optimizer_target_node_name_scope = 6;</code>
     */
    public java.lang.String getMemoryOptimizerTargetNodeNameScope() {
      java.lang.Object ref = memoryOptimizerTargetNodeNameScope_;
      if (!(ref instanceof java.lang.String)) {
        com.google.protobuf.ByteString bs =
            (com.google.protobuf.ByteString) ref;
        java.lang.String s = bs.toStringUtf8();
        memoryOptimizerTargetNodeNameScope_ = s;
        return s;
      } else {
        return (java.lang.String) ref;
      }
    }
    /**
     * <pre>
     * A node name scope for node names which are valid outputs of recompuations.
     * Inputs to nodes that match this scope may be recomputed (subject either to
     * manual annotation of those input nodes or to manual annotation and
     * heuristics depending on memory_optimization), but the nodes themselves will
     * not be recomputed. This matches any sub-scopes as well, meaning the scope
     * can appear not just as a top-level scope. For example, if the value is
     * "gradients/", the default, it will match node name "gradients/foo",
     * "foo/gradients/bar", but not "foo_gradients/"
     * </pre>
     *
     * <code>string memory_optimizer_target_node_name_scope = 6;</code>
     */
    public com.google.protobuf.ByteString
        getMemoryOptimizerTargetNodeNameScopeBytes() {
      java.lang.Object ref = memoryOptimizerTargetNodeNameScope_;
      if (ref instanceof String) {
        com.google.protobuf.ByteString b = 
            com.google.protobuf.ByteString.copyFromUtf8(
                (java.lang.String) ref);
        memoryOptimizerTargetNodeNameScope_ = b;
        return b;
      } else {
        return (com.google.protobuf.ByteString) ref;
      }
    }
    /**
     * <pre>
     * A node name scope for node names which are valid outputs of recompuations.
     * Inputs to nodes that match this scope may be recomputed (subject either to
     * manual annotation of those input nodes or to manual annotation and
     * heuristics depending on memory_optimization), but the nodes themselves will
     * not be recomputed. This matches any sub-scopes as well, meaning the scope
     * can appear not just as a top-level scope. For example, if the value is
     * "gradients/", the default, it will match node name "gradients/foo",
     * "foo/gradients/bar", but not "foo_gradients/"
     * </pre>
     *
     * <code>string memory_optimizer_target_node_name_scope = 6;</code>
     */
    public Builder setMemoryOptimizerTargetNodeNameScope(
        java.lang.String value) {
      if (value == null) {
    throw new NullPointerException();
  }
  
      memoryOptimizerTargetNodeNameScope_ = value;
      onChanged();
      return this;
    }
    /**
     * <pre>
     * A node name scope for node names which are valid outputs of recompuations.
     * Inputs to nodes that match this scope may be recomputed (subject either to
     * manual annotation of those input nodes or to manual annotation and
     * heuristics depending on memory_optimization), but the nodes themselves will
     * not be recomputed. This matches any sub-scopes as well, meaning the scope
     * can appear not just as a top-level scope. For example, if the value is
     * "gradients/", the default, it will match node name "gradients/foo",
     * "foo/gradients/bar", but not "foo_gradients/"
     * </pre>
     *
     * <code>string memory_optimizer_target_node_name_scope = 6;</code>
     */
    public Builder clearMemoryOptimizerTargetNodeNameScope() {
      
      memoryOptimizerTargetNodeNameScope_ = getDefaultInstance().getMemoryOptimizerTargetNodeNameScope();
      onChanged();
      return this;
    }
    /**
     * <pre>
     * A node name scope for node names which are valid outputs of recompuations.
     * Inputs to nodes that match this scope may be recomputed (subject either to
     * manual annotation of those input nodes or to manual annotation and
     * heuristics depending on memory_optimization), but the nodes themselves will
     * not be recomputed. This matches any sub-scopes as well, meaning the scope
     * can appear not just as a top-level scope. For example, if the value is
     * "gradients/", the default, it will match node name "gradients/foo",
     * "foo/gradients/bar", but not "foo_gradients/"
     * </pre>
     *
     * <code>string memory_optimizer_target_node_name_scope = 6;</code>
     */
    public Builder setMemoryOptimizerTargetNodeNameScopeBytes(
        com.google.protobuf.ByteString value) {
      if (value == null) {
    throw new NullPointerException();
  }
  checkByteStringIsUtf8(value);
      
      memoryOptimizerTargetNodeNameScope_ = value;
      onChanged();
      return this;
    }

    private org.tensorflow.framework.AutoParallelOptions autoParallel_ = null;
    private com.google.protobuf.SingleFieldBuilderV3<
        org.tensorflow.framework.AutoParallelOptions, org.tensorflow.framework.AutoParallelOptions.Builder, org.tensorflow.framework.AutoParallelOptionsOrBuilder> autoParallelBuilder_;
    /**
     * <pre>
     * Configures AutoParallel optimization passes either through the
     * meta-optimizer or when manually specified through the optimizers field.
     * </pre>
     *
     * <code>.tensorflow.AutoParallelOptions auto_parallel = 5;</code>
     */
    public boolean hasAutoParallel() {
      return autoParallelBuilder_ != null || autoParallel_ != null;
    }
    /**
     * <pre>
     * Configures AutoParallel optimization passes either through the
     * meta-optimizer or when manually specified through the optimizers field.
     * </pre>
     *
     * <code>.tensorflow.AutoParallelOptions auto_parallel = 5;</code>
     */
    public org.tensorflow.framework.AutoParallelOptions getAutoParallel() {
      if (autoParallelBuilder_ == null) {
        return autoParallel_ == null ? org.tensorflow.framework.AutoParallelOptions.getDefaultInstance() : autoParallel_;
      } else {
        return autoParallelBuilder_.getMessage();
      }
    }
    /**
     * <pre>
     * Configures AutoParallel optimization passes either through the
     * meta-optimizer or when manually specified through the optimizers field.
     * </pre>
     *
     * <code>.tensorflow.AutoParallelOptions auto_parallel = 5;</code>
     */
    public Builder setAutoParallel(org.tensorflow.framework.AutoParallelOptions value) {
      if (autoParallelBuilder_ == null) {
        if (value == null) {
          throw new NullPointerException();
        }
        autoParallel_ = value;
        onChanged();
      } else {
        autoParallelBuilder_.setMessage(value);
      }

      return this;
    }
    /**
     * <pre>
     * Configures AutoParallel optimization passes either through the
     * meta-optimizer or when manually specified through the optimizers field.
     * </pre>
     *
     * <code>.tensorflow.AutoParallelOptions auto_parallel = 5;</code>
     */
    public Builder setAutoParallel(
        org.tensorflow.framework.AutoParallelOptions.Builder builderForValue) {
      if (autoParallelBuilder_ == null) {
        autoParallel_ = builderForValue.build();
        onChanged();
      } else {
        autoParallelBuilder_.setMessage(builderForValue.build());
      }

      return this;
    }
    /**
     * <pre>
     * Configures AutoParallel optimization passes either through the
     * meta-optimizer or when manually specified through the optimizers field.
     * </pre>
     *
     * <code>.tensorflow.AutoParallelOptions auto_parallel = 5;</code>
     */
    public Builder mergeAutoParallel(org.tensorflow.framework.AutoParallelOptions value) {
      if (autoParallelBuilder_ == null) {
        if (autoParallel_ != null) {
          autoParallel_ =
            org.tensorflow.framework.AutoParallelOptions.newBuilder(autoParallel_).mergeFrom(value).buildPartial();
        } else {
          autoParallel_ = value;
        }
        onChanged();
      } else {
        autoParallelBuilder_.mergeFrom(value);
      }

      return this;
    }
    /**
     * <pre>
     * Configures AutoParallel optimization passes either through the
     * meta-optimizer or when manually specified through the optimizers field.
     * </pre>
     *
     * <code>.tensorflow.AutoParallelOptions auto_parallel = 5;</code>
     */
    public Builder clearAutoParallel() {
      if (autoParallelBuilder_ == null) {
        autoParallel_ = null;
        onChanged();
      } else {
        autoParallel_ = null;
        autoParallelBuilder_ = null;
      }

      return this;
    }
    /**
     * <pre>
     * Configures AutoParallel optimization passes either through the
     * meta-optimizer or when manually specified through the optimizers field.
     * </pre>
     *
     * <code>.tensorflow.AutoParallelOptions auto_parallel = 5;</code>
     */
    public org.tensorflow.framework.AutoParallelOptions.Builder getAutoParallelBuilder() {
      
      onChanged();
      return getAutoParallelFieldBuilder().getBuilder();
    }
    /**
     * <pre>
     * Configures AutoParallel optimization passes either through the
     * meta-optimizer or when manually specified through the optimizers field.
     * </pre>
     *
     * <code>.tensorflow.AutoParallelOptions auto_parallel = 5;</code>
     */
    public org.tensorflow.framework.AutoParallelOptionsOrBuilder getAutoParallelOrBuilder() {
      if (autoParallelBuilder_ != null) {
        return autoParallelBuilder_.getMessageOrBuilder();
      } else {
        return autoParallel_ == null ?
            org.tensorflow.framework.AutoParallelOptions.getDefaultInstance() : autoParallel_;
      }
    }
    /**
     * <pre>
     * Configures AutoParallel optimization passes either through the
     * meta-optimizer or when manually specified through the optimizers field.
     * </pre>
     *
     * <code>.tensorflow.AutoParallelOptions auto_parallel = 5;</code>
     */
    private com.google.protobuf.SingleFieldBuilderV3<
        org.tensorflow.framework.AutoParallelOptions, org.tensorflow.framework.AutoParallelOptions.Builder, org.tensorflow.framework.AutoParallelOptionsOrBuilder> 
        getAutoParallelFieldBuilder() {
      if (autoParallelBuilder_ == null) {
        autoParallelBuilder_ = new com.google.protobuf.SingleFieldBuilderV3<
            org.tensorflow.framework.AutoParallelOptions, org.tensorflow.framework.AutoParallelOptions.Builder, org.tensorflow.framework.AutoParallelOptionsOrBuilder>(
                getAutoParallel(),
                getParentForChildren(),
                isClean());
        autoParallel_ = null;
      }
      return autoParallelBuilder_;
    }

    private com.google.protobuf.LazyStringList optimizers_ = com.google.protobuf.LazyStringArrayList.EMPTY;
    private void ensureOptimizersIsMutable() {
      if (!((bitField0_ & 0x00001000) == 0x00001000)) {
        optimizers_ = new com.google.protobuf.LazyStringArrayList(optimizers_);
        bitField0_ |= 0x00001000;
       }
    }
    /**
     * <pre>
     * If non-empty, will use this as an alternative way to specify a list of
     * optimizations to turn on and the order of the optimizations (replacing the
     * meta-optimizer).
     * Of the RewriterConfig options, only the AutoParallel configuration options
     * (the auto_parallel field) apply to manually requested optimization passes
     * ("autoparallel"). Memory optimization passes ("memory") invoked here are
     * not configurable (in contrast to memory optimization passes through the
     * meta-optimizer) and act only on manual op annotations.
     * Custom registered optimizers will be run after the base optimizers, in
     * the order that they are specified.
     * </pre>
     *
     * <code>repeated string optimizers = 100;</code>
     */
    public com.google.protobuf.ProtocolStringList
        getOptimizersList() {
      return optimizers_.getUnmodifiableView();
    }
    /**
     * <pre>
     * If non-empty, will use this as an alternative way to specify a list of
     * optimizations to turn on and the order of the optimizations (replacing the
     * meta-optimizer).
     * Of the RewriterConfig options, only the AutoParallel configuration options
     * (the auto_parallel field) apply to manually requested optimization passes
     * ("autoparallel"). Memory optimization passes ("memory") invoked here are
     * not configurable (in contrast to memory optimization passes through the
     * meta-optimizer) and act only on manual op annotations.
     * Custom registered optimizers will be run after the base optimizers, in
     * the order that they are specified.
     * </pre>
     *
     * <code>repeated string optimizers = 100;</code>
     */
    public int getOptimizersCount() {
      return optimizers_.size();
    }
    /**
     * <pre>
     * If non-empty, will use this as an alternative way to specify a list of
     * optimizations to turn on and the order of the optimizations (replacing the
     * meta-optimizer).
     * Of the RewriterConfig options, only the AutoParallel configuration options
     * (the auto_parallel field) apply to manually requested optimization passes
     * ("autoparallel"). Memory optimization passes ("memory") invoked here are
     * not configurable (in contrast to memory optimization passes through the
     * meta-optimizer) and act only on manual op annotations.
     * Custom registered optimizers will be run after the base optimizers, in
     * the order that they are specified.
     * </pre>
     *
     * <code>repeated string optimizers = 100;</code>
     */
    public java.lang.String getOptimizers(int index) {
      return optimizers_.get(index);
    }
    /**
     * <pre>
     * If non-empty, will use this as an alternative way to specify a list of
     * optimizations to turn on and the order of the optimizations (replacing the
     * meta-optimizer).
     * Of the RewriterConfig options, only the AutoParallel configuration options
     * (the auto_parallel field) apply to manually requested optimization passes
     * ("autoparallel"). Memory optimization passes ("memory") invoked here are
     * not configurable (in contrast to memory optimization passes through the
     * meta-optimizer) and act only on manual op annotations.
     * Custom registered optimizers will be run after the base optimizers, in
     * the order that they are specified.
     * </pre>
     *
     * <code>repeated string optimizers = 100;</code>
     */
    public com.google.protobuf.ByteString
        getOptimizersBytes(int index) {
      return optimizers_.getByteString(index);
    }
    /**
     * <pre>
     * If non-empty, will use this as an alternative way to specify a list of
     * optimizations to turn on and the order of the optimizations (replacing the
     * meta-optimizer).
     * Of the RewriterConfig options, only the AutoParallel configuration options
     * (the auto_parallel field) apply to manually requested optimization passes
     * ("autoparallel"). Memory optimization passes ("memory") invoked here are
     * not configurable (in contrast to memory optimization passes through the
     * meta-optimizer) and act only on manual op annotations.
     * Custom registered optimizers will be run after the base optimizers, in
     * the order that they are specified.
     * </pre>
     *
     * <code>repeated string optimizers = 100;</code>
     */
    public Builder setOptimizers(
        int index, java.lang.String value) {
      if (value == null) {
    throw new NullPointerException();
  }
  ensureOptimizersIsMutable();
      optimizers_.set(index, value);
      onChanged();
      return this;
    }
    /**
     * <pre>
     * If non-empty, will use this as an alternative way to specify a list of
     * optimizations to turn on and the order of the optimizations (replacing the
     * meta-optimizer).
     * Of the RewriterConfig options, only the AutoParallel configuration options
     * (the auto_parallel field) apply to manually requested optimization passes
     * ("autoparallel"). Memory optimization passes ("memory") invoked here are
     * not configurable (in contrast to memory optimization passes through the
     * meta-optimizer) and act only on manual op annotations.
     * Custom registered optimizers will be run after the base optimizers, in
     * the order that they are specified.
     * </pre>
     *
     * <code>repeated string optimizers = 100;</code>
     */
    public Builder addOptimizers(
        java.lang.String value) {
      if (value == null) {
    throw new NullPointerException();
  }
  ensureOptimizersIsMutable();
      optimizers_.add(value);
      onChanged();
      return this;
    }
    /**
     * <pre>
     * If non-empty, will use this as an alternative way to specify a list of
     * optimizations to turn on and the order of the optimizations (replacing the
     * meta-optimizer).
     * Of the RewriterConfig options, only the AutoParallel configuration options
     * (the auto_parallel field) apply to manually requested optimization passes
     * ("autoparallel"). Memory optimization passes ("memory") invoked here are
     * not configurable (in contrast to memory optimization passes through the
     * meta-optimizer) and act only on manual op annotations.
     * Custom registered optimizers will be run after the base optimizers, in
     * the order that they are specified.
     * </pre>
     *
     * <code>repeated string optimizers = 100;</code>
     */
    public Builder addAllOptimizers(
        java.lang.Iterable<java.lang.String> values) {
      ensureOptimizersIsMutable();
      com.google.protobuf.AbstractMessageLite.Builder.addAll(
          values, optimizers_);
      onChanged();
      return this;
    }
    /**
     * <pre>
     * If non-empty, will use this as an alternative way to specify a list of
     * optimizations to turn on and the order of the optimizations (replacing the
     * meta-optimizer).
     * Of the RewriterConfig options, only the AutoParallel configuration options
     * (the auto_parallel field) apply to manually requested optimization passes
     * ("autoparallel"). Memory optimization passes ("memory") invoked here are
     * not configurable (in contrast to memory optimization passes through the
     * meta-optimizer) and act only on manual op annotations.
     * Custom registered optimizers will be run after the base optimizers, in
     * the order that they are specified.
     * </pre>
     *
     * <code>repeated string optimizers = 100;</code>
     */
    public Builder clearOptimizers() {
      optimizers_ = com.google.protobuf.LazyStringArrayList.EMPTY;
      bitField0_ = (bitField0_ & ~0x00001000);
      onChanged();
      return this;
    }
    /**
     * <pre>
     * If non-empty, will use this as an alternative way to specify a list of
     * optimizations to turn on and the order of the optimizations (replacing the
     * meta-optimizer).
     * Of the RewriterConfig options, only the AutoParallel configuration options
     * (the auto_parallel field) apply to manually requested optimization passes
     * ("autoparallel"). Memory optimization passes ("memory") invoked here are
     * not configurable (in contrast to memory optimization passes through the
     * meta-optimizer) and act only on manual op annotations.
     * Custom registered optimizers will be run after the base optimizers, in
     * the order that they are specified.
     * </pre>
     *
     * <code>repeated string optimizers = 100;</code>
     */
    public Builder addOptimizersBytes(
        com.google.protobuf.ByteString value) {
      if (value == null) {
    throw new NullPointerException();
  }
  checkByteStringIsUtf8(value);
      ensureOptimizersIsMutable();
      optimizers_.add(value);
      onChanged();
      return this;
    }
    public final Builder setUnknownFields(
        final com.google.protobuf.UnknownFieldSet unknownFields) {
      return this;
    }

    public final Builder mergeUnknownFields(
        final com.google.protobuf.UnknownFieldSet unknownFields) {
      return this;
    }


    // @@protoc_insertion_point(builder_scope:tensorflow.RewriterConfig)
  }

  // @@protoc_insertion_point(class_scope:tensorflow.RewriterConfig)
  private static final org.tensorflow.framework.RewriterConfig DEFAULT_INSTANCE;
  static {
    DEFAULT_INSTANCE = new org.tensorflow.framework.RewriterConfig();
  }

  public static org.tensorflow.framework.RewriterConfig getDefaultInstance() {
    return DEFAULT_INSTANCE;
  }

  private static final com.google.protobuf.Parser<RewriterConfig>
      PARSER = new com.google.protobuf.AbstractParser<RewriterConfig>() {
    public RewriterConfig parsePartialFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
        return new RewriterConfig(input, extensionRegistry);
    }
  };

  public static com.google.protobuf.Parser<RewriterConfig> parser() {
    return PARSER;
  }

  @java.lang.Override
  public com.google.protobuf.Parser<RewriterConfig> getParserForType() {
    return PARSER;
  }

  public org.tensorflow.framework.RewriterConfig getDefaultInstanceForType() {
    return DEFAULT_INSTANCE;
  }

}

